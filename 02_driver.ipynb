{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae405715-4498-471d-8da3-2132faeb4ff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Tool-calling Agent\n",
    "\n",
    "This is an auto-generated notebook created by an AI Playground export.\n",
    "\n",
    "This notebook uses [Mosaic AI Agent Framework](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/build-genai-apps) to recreate your agent from the AI Playground. It  demonstrates how to develop, manually test, evaluate, log, and deploy a tool-calling agent in LangGraph.\n",
    "\n",
    "The agent code implements [MLflow's ChatAgent](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.ChatAgent) interface, a Databricks-recommended open-source standard that simplifies authoring multi-turn conversational agents, and is fully compatible with Mosaic AI agent framework functionality.\n",
    "\n",
    " **_NOTE:_**  This notebook uses LangChain, but AI Agent Framework is compatible with any agent authoring framework, including LlamaIndex or pure Python agents written with the OpenAI SDK.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Address all `TODO`s in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea6dcad1-a59d-449d-9bd7-9af5f1701f1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow-skinny[databricks]==3.1.3 langgraph==0.3.4 langgraph-checkpoint-postgres databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb1011e3-9605-4ed4-8611-279bc85a1717",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the agent in code\n",
    "Below we define our agent code in a single cell, enabling us to easily write it to a local Python file for subsequent logging and deployment using the `%%writefile` magic command.\n",
    "\n",
    "For more examples of tools to add to your agent, see [docs](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/agent-tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69e3024f-8a15-43c1-a7b8-b07f7af0d5a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "from typing import Any, Generator, Optional, Sequence, Union, Dict\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    VectorSearchRetrieverTool,\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "import os\n",
    "import logging\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "################################################################\n",
    "#### Lakebase Part\n",
    "###############################################################\n",
    "\n",
    "import uuid\n",
    "import logging\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import requests\n",
    "\n",
    "def get_db_uri():\n",
    "\n",
    "    w = WorkspaceClient(\n",
    "        host=os.getenv(\"HOST_URL\"),\n",
    "        azure_tenant_id=os.getenv(\"AZURE_TENANT_ID\"),\n",
    "        azure_client_id=os.getenv(\"AZURE_CLIENT_ID\"),\n",
    "        azure_client_secret=os.getenv(\"AZURE_CLIENT_SECRET\"),\n",
    "        auth_type=\"azure-client-secret\",\n",
    "        )\n",
    "\n",
    "    instance_name = \"stateful-agent-backend\"\n",
    "\n",
    "    cred = w.database.generate_database_credential(\n",
    "        request_id=str(uuid.uuid4()), \n",
    "        instance_names=[instance_name],\n",
    "    )\n",
    "    \n",
    "    instance = w.database.get_database_instance(name=instance_name)\n",
    "\n",
    "    DB_URI = (\n",
    "        f\"postgresql://{os.getenv(\"AZURE_CLIENT_ID\")}:{cred.token}\"\n",
    "        f\"@instance-75eabdf6-13f6-43a9-a9b8-d844c306d095.database.azuredatabricks.net:5432/\"\n",
    "        f\"databricks_postgres?sslmode=require\"\n",
    "    )\n",
    "\n",
    "    return DB_URI\n",
    "\n",
    "checkpointer = PostgresSaver.from_conn_string(get_db_uri())\n",
    "\n",
    "# some of this will need to be on the fly - only a one hour token??\n",
    "\n",
    "################################################################\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "system_prompt = \"\"\"\"\"\"\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent, enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/agent-tool\n",
    "###############################################################################\n",
    "tools = []\n",
    "\n",
    "# You can use UDFs in Unity Catalog as agent tools\n",
    "uc_tool_names = []\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools.extend(uc_toolkit.tools)\n",
    "\n",
    "# # (Optional) Use Databricks vector search indexes as tools\n",
    "# # See https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/unstructured-retrieval-tools\n",
    "# # for details\n",
    "#\n",
    "# # TODO: Add vector search indexes as tools or delete this block\n",
    "# vector_search_tools = [\n",
    "#         VectorSearchRetrieverTool(\n",
    "#         index_name=\"\",\n",
    "#         # filters=\"...\"\n",
    "#     )\n",
    "# ]\n",
    "# tools.extend(vector_search_tools)\n",
    "\n",
    "#####################\n",
    "## Define agent logic\n",
    "#####################\n",
    "\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Union[Sequence[BaseTool], ToolNode],\n",
    "    system_prompt: Optional[str] = None,\n",
    "    checkpointer: Optional[PostgresSaver] = None,\n",
    ") -> CompiledGraph:\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # Define the function that determines which node to go to\n",
    "    def should_continue(state: ChatAgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If there are function calls, continue. else, end\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "            + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | model\n",
    "\n",
    "    def call_model(\n",
    "        state: ChatAgentState,\n",
    "        config: RunnableConfig,\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))\n",
    "\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"tools\",\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    if checkpointer:\n",
    "        return workflow.compile(checkpointer=checkpointer)\n",
    "    else:\n",
    "        return workflow.compile()\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self): #, agent: CompiledStateGraph):\n",
    "        self.agent = None #agent\n",
    "\n",
    "    def _make_config(\n",
    "        self, \n",
    "        thread_id, \n",
    "        configurable_kwargs: Optional[dict] = None, \n",
    "        metadata_kwargs: Optional[dict] = None):\n",
    "        if not configurable_kwargs:\n",
    "            configurable_kwargs = {}\n",
    "        if not metadata_kwargs:\n",
    "            metadata_kwargs = {}\n",
    "        configurable_dict = configurable_kwargs\n",
    "        metadata_dict = metadata_kwargs\n",
    "        configurable_dict.update({'thread_id': thread_id})\n",
    "        config = {\n",
    "            \"configurable\": configurable_dict,\n",
    "            \"metadata\": metadata_dict\n",
    "        }\n",
    "        return config\n",
    "    \n",
    "    def handle_custom_inputs_as_config(self, custom_inputs: Optional[Dict[str,Any]] = None):\n",
    "        if not custom_inputs:\n",
    "            logging.warning('no custom inputs provided - will start a new thread_id')\n",
    "            custom_inputs = dict()\n",
    "\n",
    "        if \"thread_id\" not in custom_inputs:\n",
    "            logging.warning('no thread_id provided, creating one')\n",
    "            custom_inputs['thread_id'] = str(uuid.uuid4())\n",
    "        else:\n",
    "            logging.info(f'using thread_id {custom_inputs[\"thread_id\"]}')\n",
    "\n",
    "        thread_id = custom_inputs.pop(\"thread_id\")\n",
    "        metadata_dict = custom_inputs\n",
    "        config = self._make_config(thread_id=thread_id, metadata_kwargs=metadata_dict)\n",
    "        return config\n",
    "\n",
    "    def get_history_of_thread(self, thread_id):\n",
    "        db_uri = get_db_uri()\n",
    "        with PostgresSaver.from_conn_string(db_uri) as checkpointer:\n",
    "            agent = create_tool_calling_agent(llm, tools, system_prompt, checkpointer)\n",
    "\n",
    "            history = list(\n",
    "                agent.get_state_history(\n",
    "                self.handle_custom_inputs_as_config(\n",
    "                    custom_inputs= {\n",
    "                    'thread_id' : thread_id,\n",
    "                    })))\n",
    "\n",
    "            if history:\n",
    "                previous_messages = history[0].values['messages']\n",
    "            else:\n",
    "                previous_messages = []\n",
    "\n",
    "        return previous_messages\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        # self.get_agent(llm, tools, system_prompt)\n",
    "        db_uri = get_db_uri()\n",
    "        with PostgresSaver.from_conn_string(db_uri) as checkpointer:\n",
    "\n",
    "            agent = create_tool_calling_agent(llm, tools, system_prompt, checkpointer)\n",
    "            request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "            print(\"custom inputs = \", custom_inputs)\n",
    "            config = self.handle_custom_inputs_as_config(custom_inputs=custom_inputs)\n",
    "\n",
    "            messages = []\n",
    "            for event in agent.stream(request, config, stream_mode=\"updates\"):\n",
    "                for node_data in event.values():\n",
    "                    messages.extend(\n",
    "                        ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                    )\n",
    "            return ChatAgentResponse(messages=messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        db_uri = get_db_uri()\n",
    "        with PostgresSaver.from_conn_string(db_uri) as checkpointer:\n",
    "            agent = create_tool_calling_agent(llm, tools, system_prompt, checkpointer)\n",
    "\n",
    "            request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "            print(\"custom inputs = \", custom_inputs)\n",
    "            config = self.handle_custom_inputs_as_config(custom_inputs=custom_inputs)\n",
    "\n",
    "\n",
    "            for event in agent.stream(request, config, stream_mode=\"updates\"):\n",
    "                for node_data in event.values():\n",
    "                    yield from (\n",
    "                        ChatAgentChunk(**{\"delta\": msg}) for msg in node_data[\"messages\"]\n",
    "                    )\n",
    "\n",
    "# Create the agent object, and specify it as the agent object to use when\n",
    "# loading the agent back for inference via mlflow.models.set_model()\n",
    "AGENT = LangGraphChatAgent() #agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a14e646-7210-4a18-96dc-1cf0dd79b427",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output. Since this notebook called `mlflow.langchain.autolog()` you can view the trace for each step the agent takes.\n",
    "\n",
    "Replace this placeholder input with an appropriate domain-specific example for your agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a537ffb-e7ee-47b3-9ab3-89bee99e6219",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41c49637-42af-4d12-bb52-2721f1780e98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MODIFY THESE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed9af17c-8a17-4a9b-9ef0-75ab8ea3f9a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dbruntime.databricks_repl_context import get_context\n",
    "\n",
    "# TODO: set WORKSPACE_URL manually if it cannot be inferred from the current notebook\n",
    "WORKSPACE_URL = None\n",
    "if WORKSPACE_URL is None:\n",
    "  workspace_url_hostname = get_context().workspaceUrl\n",
    "  assert workspace_url_hostname is not None, \"Unable to look up current workspace URL. This can happen if running against serverless compute. Manually set WORKSPACE_URL yourself above, or run this notebook against classic compute\"\n",
    "  WORKSPACE_URL = f\"https://{workspace_url_hostname}\"\n",
    "\n",
    "# TODO: set secret_scope_name and secret_key_name to access your PAT\n",
    "secret_scope_name = \"ryuta\"\n",
    "secret_key_azure_tenant_id = \"azure_tenant_id\"\n",
    "secret_key_azure_client_id = \"azure_client_id\"\n",
    "secret_key_azure_client_secret = \"azure_client_secret\"\n",
    "\n",
    "os.environ[\"HOST_URL\"] = WORKSPACE_URL\n",
    "os.environ[\"AZURE_TENANT_ID\"] = dbutils.secrets.get(scope=secret_scope_name, key=secret_key_azure_tenant_id)\n",
    "os.environ[\"AZURE_CLIENT_ID\"] = dbutils.secrets.get(scope=secret_scope_name, key=secret_key_azure_client_id)\n",
    "os.environ[\"AZURE_CLIENT_SECRET\"] = dbutils.secrets.get(scope=secret_scope_name, key=secret_key_azure_client_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f631f9dc-3400-415f-a390-2a0f0de3775c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from agent import AGENT\n",
    "\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "AGENT.predict(\n",
    "  {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}],\n",
    "    \"custom_inputs\" : {\n",
    "      'user_id': 'ryuta.yoshimatsu@databricks.com',\n",
    "      'thread_id': thread_id,\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "355da523-35a7-4f49-a072-bb999a84b06b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict(\n",
    "  {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What are some best places to visit in Japan in September?\"}],\n",
    "    \"custom_inputs\" : {\n",
    "      'user_id': 'ryuta.yoshimatsu@databricks.com',\n",
    "      'thread_id': thread_id,\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40e3e3ae-b0a7-41f8-99f0-35cc206eaff6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict(\n",
    "  {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What else do you recommend?\"}],\n",
    "    \"custom_inputs\" : {\n",
    "      'user_id': 'ryuta.yoshimatsu@databricks.com',\n",
    "      'thread_id': thread_id,\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59b066fd-b393-43aa-adc7-c8fd37464048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict(\n",
    "  {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Give me more recommendations.\"}],\n",
    "    \"custom_inputs\" : {\n",
    "      'user_id': 'ryuta.yoshimatsu@databricks.com',\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a6b5384-c6e7-44cd-b622-5f0a4971db97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Log the `agent` as an MLflow model\n",
    "Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "- **TODO**: If your Unity Catalog Function queries a [vector search index](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/unstructured-retrieval-tools) or leverages [external functions](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/external-connection-tools), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See [docs](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/log-agent#specify-resources-for-automatic-authentication-passthrough) for more details.\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0d6da08-962d-4588-a7f6-6f9254f16e79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent import LLM_ENDPOINT_NAME, tools\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from pkg_resources import get_distribution\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        # TODO: If the UC function includes dependencies like external connection or vector search, please include them manually.\n",
    "        # See the TODO in the markdown above for more information.\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}],\n",
    "    \"custom_inputs\" : {\n",
    "      'user_id': 'ryuta.yoshimatsu@databricks.com',\n",
    "    }\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            f\"mlflow=={get_distribution('mlflow').version}\",\n",
    "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "            f\"pydantic=={get_distribution('pydantic').version}\",\n",
    "            f\"langgraph-checkpoint-postgres=={get_distribution('langgraph-checkpoint-postgres').version}\",\n",
    "            f\"psycopg[binary]=={get_distribution('psycopg').version}\", # serving endpoints don't have this and so must add it\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf2e2725-e1fb-4a91-830d-3b036d259f3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with [Agent Evaluation](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/)\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics.\n",
    "\n",
    "Evaluate your agent with one of our [predefined LLM scorers](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/predefined-judge-scorers), or try adding [custom metrics](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/custom-scorers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8654dbc-aa82-470c-bb17-488dfd4c1029",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# from mlflow.genai.scorers import RelevanceToQuery, Safety, RetrievalRelevance, RetrievalGroundedness\n",
    "\n",
    "# eval_dataset = [\n",
    "#     {\n",
    "#         \"inputs\": {\n",
    "#             \"messages\": [{\"role\": \"user\", \"content\": \"hello!\"}],\n",
    "#             \"custom_inputs\" : {\n",
    "#             'user_id': 'peter.hawkins@databricks.com',\n",
    "#             }\n",
    "#         },\n",
    "#         \"expected_response\": None\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# eval_results = mlflow.genai.evaluate(\n",
    "#     data=eval_dataset,\n",
    "#     predict_fn=lambda messages: AGENT.predict({\"messages\": messages}),\n",
    "#     scorers=[RelevanceToQuery(), Safety()], # add more scorers here if they're applicable\n",
    "# )\n",
    "\n",
    "# Review the evaluation results in the MLfLow UI (see console output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e340013c-6af2-49f4-938a-6388d5519a7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04ff20f4-f448-4c70-9228-b7ff6928de72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"ryuta\"\n",
    "schema = \"agents\"\n",
    "model_name = \"stateful_agent\"\n",
    "\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19ad7d01-b8fc-4ebc-8eeb-3aff40d7e136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a669659-8734-43f2-ae42-e330b7f4067a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "agents.deploy(\n",
    "  UC_MODEL_NAME, \n",
    "  uc_registered_model_info.version, \n",
    "  tags = {\"endpointSource\": \"playground\"},\n",
    "  environment_vars={\n",
    "        \"HOST_URL\": f\"{WORKSPACE_URL}\",\n",
    "        \"AZURE_TENANT_ID\": f\"{{{{secrets/{secret_scope_name}/{secret_key_azure_tenant_id}}}}}\",\n",
    "        \"AZURE_CLIENT_ID\": f\"{{{{secrets/{secret_scope_name}/{secret_key_azure_client_id}}}}}\",\n",
    "        \"AZURE_CLIENT_SECRET\": f\"{{{{secrets/{secret_scope_name}/{secret_key_azure_client_secret}}}}}\",    \n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cebfe0ff-b0ec-43aa-917c-e4e5570518ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See [docs](https://learn.microsoft.com/azure/databricks/generative-ai/deploy-agent) for details"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_driver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}